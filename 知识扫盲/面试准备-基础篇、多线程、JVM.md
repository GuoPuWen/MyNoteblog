## 1.String、StringBuffer、StringBuilder

①从可变与不可变角度述说(String 不可变，StringBuffer，StringBuilder可变)

②从线程是否安全方面，StringBuffer安全，StringBuilder不安全，同时扩展到效率问题

③从String的+法进行述说，底层使用了StringBuilder(线程不安全，但是效率高)

## 2. JDK1.7和JDK1.8

可以聊一聊jdk1.8的新特性：

- lambda表达式、函数式接口、方法引用
- stream流式编程
- HashMap之间的区别：jdk1.7使用数组+链表，jdk1.8数组＋链表+红黑树
- ConcurrentHashMap之间的区别：jdk1.7使用的是数组+链表，同时使用分段锁，锁住每一个Segment，用的是ReentrantLock ，jdk1.8使用的是数组+链表+红黑树，锁住每一个头结点，用的是Synchronized
- 从虚拟机的角度，永久移除永久代，而是使用本地内存的元空间
- 新的日期时间API

## 3.Java线程之间的通信方式

- volatile：使用volatile，volatile保证了可见性、一致性，不保证原子性，Java内存模型规定，每个线程都有自己的一个工作区，而要修改主存的变量必须在自己的工作区内进行，然后再将工作区内的变量刷新到主存中，使用volatile可以强制刷新，volatile保证两点：①所有线程在修改完变量之后，强制刷新到主存中 ② 使用volatile修饰的变量在修改前必须重新读取主存中的值，让数据是最新的
- wait/notifiy,notifiyAll；Lcok锁的Contional机制；LockSupport方式：三者之间的区别，wait/notifiy,notifiyAl不能指定唤醒，Lcok锁的Contional机制可以指定唤醒，前面两个都要在加锁的场景下进行使用，LockSupport方式可以直接调用，本质是使用一个许可证permi
- join方式：就是说当前执行的线程必须等待调用join方法的线程执行完之后在执行，使用join可以控制两个线程之间的执行顺序，本质上还是基于通知唤醒机制的
- ThrealLocal：使用ThrealLocal可以将当前线程绑定一个变量，其实上是线程内部不同方法之间进行绑定
- JUC下的并发工具类：CountDownLatch等所有线程结束后当前线程才能执行、CycleBarrier当所有线程开始工作时才当前线程才执行、Semaphore信号量机制用于对共享资源的互斥使用可以举例停车场的例子
- 管道通信：使用java.io.PipedInputStream 和 java.io.PipedOutputStream进行通信

## 4.Lixnu下进程之间的通信方式

- 管道/匿名管道：用于父子进程之间的通信
- 有名管道：解决匿名管道只能用于父子进程之间通信的问题，可以用于任何进程之间的通信，以磁盘文件的方式存在
- 信号量：维护一个计数器，用于控制多个进程对共享资源的访问方式
- 信号：一般用于通知进程某个事件已经发生
- 消息队列：维护一个链表，存在与内核中，克服信号承载的消息量少，管道只能接受无格式字节流，缓冲区大小受限这些缺点
- 共享内存：使用一些同步机制(锁、信号量)控制多个进程可以访问同一块内存区域，实现不同进程之间的通信
- 套接字：用于网络中的通信

## 5. 频繁触发fullGC可能存在什么问题？如何排查

触发fullGC的原因：

- 程序执行了System.gc()
- 执行了Jmap命令
- 有大对象的产生，大对象直接进入老年代，导致内存不足 
- 程序中出现内存泄漏，导致一些内存无法回收，或者老年代出现了很多内存碎片

如何排查：

- 查看jvm参数设置问题，检查新生代、老年代之间的比例是否有问题(-XX:NewRatio)
- 查看GC日志，分析频繁触发Full GC的原因
- 使用jmap存储dump存储快照，然后使用jvisualvm进行排查问题，查看是否有大对象或者

## 6.SpringMVC的工作原理？

1. 请求发送到前端控制器中(DispatchServlet)中，前端控制器是请求流程的主管，负责各个组件之间的通信
2. 前端控制器将请求交给处理器映射器，处理器映射器返回对应的处理器
3. 接着请求交给处理器适配器，由处理器适配器找到真正的处理器Handle
4. 处理器处理请求，返回一个ModelAndView
5. 视图解析器解析ModelAndView得到视图
6. 最后将视图进行渲染，得到真正的页面，最后有前端控制器返回给客户端

其中涉及到了很多组件：前端控制器、处理器映射器、处理器适配器、处理器、视图解析器、视图渲染器

## 7.浏览器输入url之后发生的过程

当浏览器输入url回车之后，主要会进行如下步骤：

1. DNS域名解析：首先浏览器将一些url的字段进行补齐，端口号、协议名称等等，然后查找最近的缓存上是否已经有对应的域名解析，浏览器本地缓存、电脑上host文件上，接着查看本地服务器上是否有缓存。如果都没有，那么使用递归查询，将解析域名的任务交给本地服务器，依次迭代查询根域名服务器、顶级域名服务器、权限域名服务器，最终得到对应的ip地址、
2. 建立TCP的连接：使用ARP寻址协议找到对应ip的服务器的mac地址，然后封装成数据报文，准备进行TCP的三次握手过程建立连接，首先由客户端发送一个SYN请求报文，服务端被动打开连接，同时发送一个SYN、ACK的一个确认报文，客户端收到之后也向服务器端发送一个ACK确认报文，那么TCP的连接就已经确认
3. 发送HTTP请求，这时封装好HTTP请求报文，发送给服务端
4. 服务端返回结果，如果这时一个短连接则进行TCP的四次挥手过程关闭连接，首先由客户端发送一个FIN请求报文发送给服务端，接着服务端也发送一个ACK确认报文给客户端，这个时候从客户端到服务端之间的连接已经关闭，接着服务器向客户端发送一个FIN终止报文，客户端也回应一个ACK确认报文，那么服务器端到客户端的连接也关闭了
5. 浏览器进行渲染页面

## 8.lock锁与sync锁

- 两者都是可重入锁，也就是说自己已经获取锁了，还可以再次获取自己的内部锁

- Synchronized是依赖于JVM层面的锁，基于moniter的获取与释放获得锁的机制，ReentrantLock 是jdk1.5以来提供的API层面的锁，可以通过查看源码获取ReentrantLock 的实现原理
- 因为ReentrantLock 是API层面的锁，所以它比Synchronized增加了一些高级功能：
  - ①等待可中断机制，虽然Synchronized也可以实现让线程终止，但是需要使用return或者抛出异常的方式让线程真正停止，而ReentrantLock 可以通过调用API来实现让线程停止 
  - ②ReentrantLock 可以指定是公平锁还是非公平锁，在使用的时候默认是非公平锁的，加入false则是公平锁 
  - ③ReentrantLock 与Synchronized同样可以实现通知等待机制，但是使用ReentrantLock 有很好的灵活性，ReentrantLock 借助Condition接口可以实现有选择的进行线程通知，在线程调度上更加灵活，而Synchronized中被通知的线程是被JVM把控的
- 性能方面，在jdk1.6Synchronized进行锁的升级，优化之后，synchronized 和 ReenTrantLock 的性能基本是持平了，也就是说性能不是选择ReenTrantLock 的因素

## 9.Java基本数据类型？取值范围

| 基本类型 | 字节数                  | 位数  | 最大值                 | 最小值     |
| -------- | ----------------------- | ----- | ---------------------- | ---------- |
| byte     | 1byte                   | 8bit  | 2^7-1                  | -2^7       |
| short    | 2byte                   | 16bit | 2^15-1                 | -2^15      |
| int      | 4byte                   | 32bit | 2^31-1                 | -2^31      |
| long     | 8byte                   | 64bit | 2^63-1                 | -2^63      |
| float    | 4byte                   | 32bit | 3.4028235E38           | 1.4E - 45  |
| double   | 8byte                   | 64bit | 1.7976931348623157E308 | 4.9E - 324 |
| char     | 2byte                   | 16bit | 2^16 - 1               | 0          |
| boolean  | 只有true和false两个取值 |       |                        |            |





## 12.如何选择垃圾回收器

- 单处理器CPU或者较小的应用内存等硬件平台不是很好的情况下，选择串行垃圾回收器

选择垃圾回收器主要的判定规则是需要选择吞吐量还是暂停时间，吞吐量是指用于运行用户代码的时间与CPU总消耗时间的比值，而暂停时间是指一个时间段内应用程序线程暂停，让GC线程执行的状态。Paralle Scavengr收集器就是一种吞吐量优先的垃圾回收器，它可以有一个可控制的吞吐量，可以高效的利用CPU的时间，适合在后台运算而不需要太多的交互的任务，例如订单处理这些。CMS回收器是一款低延迟的回收器，很适合于用户进行交互的程序，具有良好的响应速度能提升用户体验

下面说说CMS垃圾回收器的优点与缺点：

- 优点：==并发收集，低延迟==。CMS垃圾回收器一共有4个阶段：初始标记(标记被GC root关联的对象速度很快 STW)  --> 并发标记(标记和GCroots能够关联的对象，不需要STW) --> 重新标记(修正并发标记期间，因为程序运行而产生的垃圾对象) --> 并发清除(清理垃圾对象 不需要STW) 

- 缺点：

  - ①会产生内存碎片，因为CMS在清除阶段使用的是标记-清除算法，原因是在并发清除的时候，如果用标记整理内存的话，原来对象的内存地址就不能使用，导致用户的线程无法执行。在无法分配大对象的时候就会触发Full GC 
- ②对CPU资源很敏感，在并发阶段，虽然不会导致用户暂停，但是占用了一部分程序导致应用程序变慢，总吞吐量会降低
  -  ③CMS无法处理浮动垃圾，如果在并发清除阶段重新产生新的垃圾对象，这些对象没有被回收，可能导致一次Full GC 
  - ④CMS垃圾回收器不能像其他收集器一样等到堆内存满的时候才进行垃圾清除，而是当堆内存使用率达到某一阈值时，才进行回收，以确保应用进程在CMS工作的时候依然有空间支持应用程序运行，而当如果这种情况出现的话，JVM就会启动预备方案，使用Serial old收集器来重新进行老年代的垃圾回收

而G1垃圾回收器的目标是在延迟可控的情况下获取尽可能高的吞吐量，G1垃圾回收器将内存的空间看做是一个一个region，内存的回收时以refion作为单位的，使用G1作为垃圾回收器具有以下的缺点和优点：

- 优点：
  - 并发与并行兼备，并发是指GC线程可以与用户线程进行交替执行的能力，并行是指可以充分利用GC线程，有效利用多核计算能力
  - 分代收集：虽然G1把内存区域划分为一个一个regin，但是仍然是进行分代收集的
  - 空间整合：CMS回收器的缺点是使用标记-清除算法，对于G1来说，region之间是复制算法，但是整体上可以看做是一个标记-压缩算法，所以可以避免内存碎片，有利于分配大对象
  - 可预测的时间模型(软实时)，G1除了追求低停顿外，还能建立可预测的停顿时间模型，可以让使用者明确指定在一个长度为M毫秒的时间片段内，消耗在垃圾回收上的时间不超过N，并且G1跟踪各个region里面的垃圾堆的价值大小(回收这个对象与回收这个对象所需要的时间)，实现原理是在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的Region

- 缺点：G1在垃圾回收过程中产生的内存占用以及程序运行时执行负载都要比CMS更高，所以G1比较适合于具有大内存、多处理区的机器

综上所述，如何选择垃圾回收器可以从以下几点来说：

- JDK8默认的是Parallel Scavenge + Parallel Old(①通过打印GC日志 ② 使用-XX:+PrintCommandLineFlags打印命令行相关参事忽 ③ 使用jinfo -flag 垃圾回收器参数 进程ID)
- 如果内存小，或者是单核、单机程序，没有停顿时间要求，那么选择串行垃圾回收器
- 多CPU，需要高吞吐量，允许一定的停顿时间，使用并行Parallel Scavenge
- 多CPU、追求低停顿时间、需要快速响应的一些互联网应用，使用并发的CMS收集器
- 官方推荐使用G1垃圾收集器，性能高



## 13. hashCode与equals

hashCode()的作用是获取哈希码，实际上就是散列值，这个哈希码的作用是确定该对象在哈希表中的索引位置，hashCode()方法是定义在JDK的Object类上的，使用hashCode在HashMap上作用很大，因为hashmap的键值是不能重复的，首先会调用hashcode方法判断两个对象的hashcode方法是否一样，如果一样再次比较equals方法，这样就大大减少了equals的次数，相应就大大提高了执行的速度

重写equals方法的同时也要重写hashcode方法，因为两个对象相等，则hashcode值一定是相等的，但是如果两个对象的hashcode值相等，两个对象是不一定相等的，所以在equasl被重写过，也要将hashcode方法重写



## 14. 线程的运行状态

- 创建态：指创建了一个线程对象，还没有调用start方法
- 可运行态：调用了start方法，需要等待被线程调度选中吗，获取到线程的时间片
- 运行态：线程获取到了CPU的时间片，执行程序代码
- 堵塞：线程因为某种原因放弃了cpu的使用权，暂时停止运行
- 死亡：线程运行完执行的代码

## 15. 缓存一致性原理

首先是因为CPU和主存的速度不一致，然后就在CPU和主存之间加了一道高速缓存区，然后CPU每次存取指令都先在高速缓存区中存取，但是在多核CPU多线程环境下，就会存在多个线程同时修改了同一个数据的问题，这就是缓存不一致的问题，然后为了解决这个问题提出了MESI协议，MESI协议定义了4中状态：

- Modified(修改)：数据有效，但是数据被修改了，和内存中的数据不一致，最新的数据只存在于本地Cache中
- Exclusive(独享)：数据有效，数据和内存中的数据一致，数据只存在于本地Cache中
- Share(共享)：数据有效，数据和内存中的数据一致，数据存在于多个Cache中
- Invaild(无效)：数据无效，数据被标记为无效

例子：首先主存中有一份数据，当只有一个线程将数组从主存中复制到线程的Cache的时候，这个数据被标记为E就是独享的的，当有其他线程也拿到这个数据的时候，这个数据被标记为S，当有一个线程进行了数据修改的时候，这个数据就被标记为I，就是失效的，只有着线程的数据被标记为M，此时也只有这个线程的数据和主存的数据一致，所以标记为E



## 16. Java异常

异常体系的最高结构是Throwable，Throwable有两个重要的子类，Exception和Error

- Error：是值程序中无法处理的错误，表示运行过程中应用程序出现了严重的错误
- Exception：程序本身可以捕获并且可以处理的异常

而Exception这种异常可以又可以分为两类，运行时异常和编译异常

一些常见的异常：

1. ConcurrentModificationException，在遍历集合的时候使用了删除等操作，解决方法是使用迭代器自带的方法 ，原因可以说modCount
2. IOException：I/O异常
3. IndexOutOfBoundsException：数组下标越界
4. NullPointerException、ClassNotFoundException、SQLException、IllegalArgumentException、InterruptedException

常见的OOM：

- 堆区OOM
- 创建的线程过多，OOM：Unable to create new native thread
- 元空间OOM
- 直接内存OOM

## 17. 树的常见数据结构

## 18. 线程的三大特性

- 原子性：指一个操作，要么全部执行，要不都不执行
- 可见性：当多个线程访问同一个变量的时候，一个线程改变了这个变量的值，其他线程能立即看到值的变化。可以先说java的内存模型
- 有序性：程序的代码执行顺序和语句的顺序是一样的，可以说volatile的那一套

# 19.安全点

# 20.对象创建的过程

1. 类加载检查：当虚拟机遇到一条new指令之后，会去进行一些检查，比如说这个类是否被加载、链接、初始化过
2. 分配内存：当类加载检查通过之后，内存也就确定了下来，分配内存有两种方式指针碰撞和空闲列表，指针碰撞适合于堆内存完整的情况，一边是使用过的内存，一边是空闲的内存，中间有一个指针，分配对象只需要移动指针即可；空闲列表适用于堆内存不完整的情况，这就需要维护一个列表来记录那一个内存可用。同时在分配内存的时候，保证线程安全的方法有两种：CAS + 失败重试，对分配内存进行原子操作，利用CAS机制保证原子性；TLAB：堆是线程共享的空间，但是在堆上也有一块线程独占的区域，分配内存的时候可以现在堆上分配，当TLAB的空间不足的时候再利用CAS + 失败重试机制在堆共享的空间分配
3. 初始化零值：将分配的空间内存都初始化为0，一般是初始化静态变量，实例变量
4. 设置对象头：对对象头进行一些设置，对象头包括一些运行信息、类型指针、数组长度
5. 指向init初始化方法

# 21.Java内存模型语意

# 22.接口和抽象类

# 23 volatile与内存屏障

volatile能够保证内存的可见性与防止指令重排序，而volatile是如何保证内存的可见性与防止指令重排序？

使用volatile的修饰的变量通过查看字节码发现加了一条lock指令，而volatile保证可见性和防止指令重排序，我理解为有两个层面，一是JVM层面，二是操作系统层面

在Jvm层面，Java将内存模型分为主内存和工作内存，主内存是所有线程共享的，而工作内存是独占的，线程对主内存中的变量的修改必须先从主内存中拷贝一份到工作内存中，从工作内存中修改完再刷新会主存中，而JMM控制主内存与每个线程的本地内存之间的交互来保证JVM层面的可见性，也就是说使用volatile修饰的关键字在修改的时候会确保拿到的值是最新的值，在Java中有几种原子操作：

- read（将变量的值从主存中传输到工作内存）
- load（将read过来的值放入到工作内存中的副本）
- use（将工作内存中的值传给执行引擎）
- assign（将执行引擎中的值赋值给工作内存中的变量）
- store（将工作内存中的值传送给主内存中）
- write（将store传来的变量放入主内存中的变量中）

而volatile保证read、load、use三个操作必须连续出现，assign、store、write必须连续出现，从而保证每次读取的时候必须先从主存中刷新最新的值，每次写入必须同步到主存中

happens-before规则是指前一个操作的结果对于后续的结果是可见的，这个技术大大的提高了程序的执行效率，但是在多线程环境下却存在问题，最经典的是DCL模式的单例模式，如果不对这个对象加上volatile修饰的关键字，那么有可能会拿到还没有初始化的对象，因为对象的初始化的执行顺序可能会被打乱，而volatile通过内存屏障来防止指令重排序，在JVM层面的内存屏障有四种，分别是loadload、storestore、loadstore、storeload：

- loadload：确保load1装载的数据先于load2
- storestore：确保store1数据对其他处理器可见先于store2数据
- laodstore：确保load1数据装载先与store2刷新到内存
- storeload：确保store1数据对处理器可见先于load2数据装载，这是一个全能型的屏障

在操作系统层面，因为CPU与内存之间差距比较大的存取速度，所以一般都会设置缓存Cache，这样同样存在不同的CPU之间缓存的数据不一致的情况，后面加提出来了MESI缓存一致性协议，也就是将缓存的数据设置为4中状态，当一个CPU首先持有一个S的数据的时候，进行修改需要发送一个失效的消息给其他的CPU，为了避免等待其他CPU的ack 确认消息，CPU中具有store buffers，也就是说先把这些缓存失效的消息存起来，等到最后一个再发送这样就大幅度提高了效率，但是这种弱一致性在高并发的场景下也带来了可见性问题，也可以说是伪 重排序。所以CPU引入了内存屏障，主要分为三类：写屏障、读屏障和全屏障。

# 24.Switch

从jdk1.7开始switch可以使用字符串，那么switch支持的有byte int short char String，但是原理上switch只支持整形，对于char类型会将char转为ascii码，而对于String类型会先调用hashcode方法转为int类型，同时还需要进行equals的比较，所以是靠hashcode和equals完成的



# 25.如何从大量的url里面找出相同的url

首先因为url太多不可能一次性加载所有的url到内存中，可以先遍历文件对每一个url进行hash(url)然后再取模100，这样就将这个大的url文件写入到了100个文件中，所有可能相同的url都在同一个文件内，因为这是个小文件所以可以直接对这个文件进行hashset，找出相同的url

